<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="../../CSS/posts/posts.css" />
    <link rel="stylesheet" href="../../CSS/header/header.css" />
    <link href="https://fonts.googleapis.com/css?family=Montserrat:500,700&display=swap" rel="stylesheet" />
    <html xmlns="http://www.w3.org/1999/xhtml">

    </html>
    <title>Lan Sevcnikar - Blog</title>
</head>

<body>
    <div class="opening">
        <p>Hi, I'm</p>
        <h1>
            Lan Sevƒçnikar
        </h1>
        <p>I make computers do stuff</p>
    </div>
    <header class="header" id="myHeader">
        <p class="header__logo">Lan's blog</p>
        <div class="header__right">
            <a href="../../index.html" class="header__link"> Home</a>
            <a href="../../blog.html" class="header__link header__link--active">
                Blog</a>
            <a href="../../portfolio.html" class="header__link"> Portfolio</a>
        </div>
    </header>
    <div class="mainBody">
        <div class="post">
            <a href="../../blog.html" style="text-decoration: none; color: #3b3b3b;">Go back</a>
            <h1>
                Spotify song recommendation algorithms
            </h1>
            <p>
                In this post, I explore my approaches to building a song recommendation system using Spotify data. I use
                multiple approaches and compare the results
            </p>

            <h2>
                Simple approach
            </h2>
            <p>
                Firstly, I used a dataset, containing song metadata that can be found <a
                    href="https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks/data">here</a>.
                For each song you are given - next to the obvious, such as artist, year, etc. - data that spotify
                creates. Examples of it being:
            <ul>
                <li>Acousticness</li>
                <li>Danceability</li>
                <li>Energy</li>
                <li>Instrumentalness</li>
                <li>Liveness</li>
                <li>Loudness</li>
                <li>Speechiness</li>
                <li>Tempo</li>
            </ul>
            Bellow is an image, containing the distribution of the valence of the songs in the dataset.
            <img src="240424-01.png" alt="Distribution of data" style="width: 100%; height: auto;">
            </p>
            <p>
                This data was then used to create values between 0 and 1, accoring to which percentaile of the data the
                songs fell.
                With that, I got the following results:
            <div class="table-div">

                <table>
                    <tr>
                        <th>Feature</th>
                        <th>Value</th>
                    </tr>
                    <tr>
                        <td> popularity </td>
                        <td> 0.819149 </td>
                    </tr>
                    <tr>
                        <td> duration </td>
                        <td> 125.667 </td>
                    </tr>
                    <tr>
                        <td> explicit </td>
                        <td> 0 </td>
                    </tr>
                    <tr>
                        <td> danceability </td>
                        <td> 0.335015 </td>
                    </tr>
                    <tr>
                        <td> energy </td>
                        <td> 0.179 </td>
                    </tr>
                    <tr>
                        <td> key </td>
                        <td> 0.454545 </td>
                    </tr>
                    <tr>
                        <td> loudness </td>
                        <td> 0.736815 </td>
                    </tr>
                    <tr>
                        <td> mode </td>
                        <td> 1.0 </td>
                    </tr>
                    <tr>
                        <td> speechiness </td>
                        <td> 0.033574 </td>
                    </tr>
                    <tr>
                        <td> acousticness </td>
                        <td> 0.88253 </td>
                    </tr>
                    <tr>
                        <td> instrumentalness </td>
                        <td> 0.0 </td>
                    </tr>
                    <tr>
                        <td> liveness </td>
                        <td> 0.0886 </td>
                    </tr>
                    <tr>
                        <td> valence </td>
                        <td> 0.315 </td>
                    </tr>
                    <tr>
                        <td> tempo </td>
                        <td> 0.391788 </td>
                    </tr>
                    <tr>
                        <td> time_signature </td>
                        <td> 0.8 </td>
                    </tr>
                    <tr>
                        <td> musical_era </td>
                        <td> 0.3 </td>
                    </tr>
                    <tr>
                        <td> track_id </td>
                        <td> 3BQHpFgAp4l80e1XslIjNI </td>
                    </tr>
                    <tr>
                        <td> track_name </td>
                        <td> Yesterday - Remastered 2009 </td>
                    </tr>
                    <tr>
                        <td> artist_name </td>
                        <td> ['The Beatles'] </td>
                    </tr>
                </table>
            </div>
            However, this quickly showed to be bad, as using either euclidean distance or cosine similarity to compare
            songs showed to be absolutely useless:
            <h4>
                Similarity of songs to Yesterday - Remastered 2009 (The Beatles)
            </h4>
            <div class="table-div">

                <table>
                    <tr>
                        <th>Track title</th>
                        <th>Euclidean distance</th>
                        <th>Cosine similarity</th>
                    </tr>
                    <tr>
                        <td>Hey Jude</td>
                        <td>305.668</td>
                        <td>0.9999237</td>
                    </tr>
                    <tr>
                        <td>Hypnotize</td>
                        <td>104.173</td>
                        <td>0.9999492</td>
                    </tr>
                </table>
            </div>
            </p>
            <p>
                It is quite obvious that this is horrible. So I go to the second method.
            </p>
            <h2>
                Neural network approach - Word embeddings using Skip-gram
            </h2>
            <p>
                The next idea I had was to use a neural network to create word embeddings of the songs.
            </p>
            <p>
                Spotify created a dataset that contains 1 million playlists. This sounded like a perfect example, giving
                me the
                necessary data for a recommendation system. In this unsupervised task, the idea is to try and find some
                way of embedding the songs
                such that the songs that are similar are close to each other in the embedding space. At the same time,
                two songs being on many playlists together sounded like a good way to measure similarity.
            </p>
            <p>
                Each song is treated as a token, a word in a sentence. The playlists are then treated as sentences. The
                idea is to train a neural network to predict the context of a word, given the word itself. This is
                called the Skip-gram model.
                The real goal of this method is not only to find the song embeddings (something that I was quite sure
                could be found) but also
                to find some underlying structure in the data. This is because the songs are not only similar in the
                sense of their audio features, but also in the sense of the playlists they are in.
            </p>
            <p>
                An idea of that is to ask a question like <i> What song is the least like Yesterday by The Beatles </i>
                or
                <i> What song is like XXXX by YYYY if I take away ZZZZ by AAAA </i>. This is something that is not
                possible with the first method.
            </p>
            <p>
                Another thing that was of interest to me was to be able to then find some vectors that would represent
                certain concepts. The famous example of
                this is <i>A king and a man differ by the same vector as a Queen and woman</i>.
            </p>
            <h3>
                Results:
            </h3>
            <p>
                The first type of analysis I wished to preform was a very simple clustering of the songs. I used the
                K-means algorithm to cluster the songs.
                Finding the optimal k was done using a combination of the elbow method and the silhouette score. The
                results were quite good, as can be seen in the image bellow.
            </p>
            <img src="240424-02.png" alt="Silloute scores">
            <img src="240424-03.png" alt="Elbow method">
            <p>
                I chose the number of clusters to be 11, as the elbow method did not give a good, definitive answer but
                seemed to agree and the silhouette score rapidly decreased after that. With that, I then used TSNE to
                visualize the clusters both in 2D and 3D. The following images show the results (mind you, the 5% most
                extreme
                songs were removed, as they were outliers and made the visualization worse (more distant)).
            </p>
            <img src="240424-04.png" alt="2D TSNE">
            <img src="240424-05.gif" alt="3D TSNE">
            <p>
                It is notable to mention that this is clearly not the best. First and foremost, most of these songs are
                in English, which is already odd but okay, that I can chop up to
                some other reason. But in general, looking at these visualizations, it is clear that the clusters are
                not
                very good. The clusters flow into eachother, which makes sense.
            </p>
            <p>
                Another thing I then did was to find the most similar songs to a given song. I used the cosine
                similarity
                to do this. The results were good and nicely specific. Fox example, taking a popular song by The
                Beatles,
                such <i>Yesterday</i>, the songs most similar to it were other Beatles songs.
            <ul>
                <li>1. Yesterday - Remastered - The Beatles,</li>
                <li>2. With A Little Help From My Friends - Remastered - The Beatles,</li>
                <li>3. All You Need Is Love - Remastered 2009 - The Beatles,</li>
                <li>4. Vincent - Don McLean,</li>
                <li>5. While My Guitar Gently Weeps - Remastered - The Beatles.</li>
            </ul>
            Do not mind the fact that <i>Yesterday</i> is the song most similar to itself. This is because the dataset
            contains the song multiple times, as it is present on multiple albums and so has different track URIs.
            <br>
            On the other hand, taking a less popular song by them with a more specific energy, such as <i>It's Only
                Love</i> resulted in the following:
            <ul>
                <li>1. Diet Mountain Dew - Lana Del Rey,</li>
                <li>2. She Looks So Perfect - 5 Seconds of Summer,</li>
                <li>3. Picture To Burn - Taylor Swift,</li>
                <li>4. The Other Woman - Lana Del Rey,</li>
                <li>5. Same Love - feat. Mary Lambert - Macklemore & Ryan Lewis.</li>
            </ul>
            This is a really good sign as both <i>Taylor Swift</i> and <i>Lana Del Rey</i> are known for their
            specific style and energy (sad and specifically focused on love).
            </p>
            <p>
                I also created a small GUI to be able to look this up easier.
                <img src="240424-06.png" alt="GUI">
            </p>

            <p>
                The final big question was if the directions inside of that space were able to be interpreted. As in the
                classic example of word embeddings, could it answer questions like more general than just similar. So
                first is, can it answer questions like <i>What song is the least like Yesterday by The Beatles</i>. And,
                drum roll please... the songs that are the least like <i>Yesterday</i> are:
            <ul>
                <li>1. Ooh Killem - King Kendrick,</li>
                <li>2. Murder - Justin Timberlake - The 20/20 Experience,</li>
                <li>3. Bounce - Iggy Azalea,</li>
                <li>4. Cinema - Radio Edit - Benny Benassi,</li>
                <li>5. Faith - Radio Edit - Blasterjaxx.</li>
            </ul>
            Two notes on these results. Firstly, I am here assuming that the song most opposite of it is the song in all
            ways most distant to it (so the most similar to the original song's vector multiplied by -1). Secondly, the
            second
            song here openly refers to The Beatles in the line <i>Know that shit gotta be lethal / If that pussy broke
                up The Beatles</i> and I think that is pretty funny.
            </p>
            <p>Sadly, I couldn't think of a way to test the last question but to be honest, that is something that I
                will have fun with some time when there will be more time for it</p>

            <h2>
                Attention is all you need - the use of transformers for song recommendation
            </h2>
            <p>
                While the previous method turned out to be quite a success (I already have some results ready but not
                enough to post here)
                it does not solve the original task I wanted to solve. The original task was to find a way to recommend
                songs to a user.
                And while there are many approaches to this, I wanted to try and use the transformer architecture.
            </p>
            <p>
                The main reason was that I had not seen anyone doing this. The approach outlines in the previous chapter
                was also rather new but after
                a lot of digging, I was able to find a paper that was already dealing with that. But the transformer
                architecture was not used.
            </p>
            <p>
                On top of that, there has been a lot of talk a bout transformers lately, being the backbone of GPT, Bard
                and other models. This
                gave me an idea that I wanted to try that as well.
            </p>
            <h1>
                References
            </h1>
            <ul>
                <li style="word-wrap: break-word;"> <a
                        href="https://research.atspotify.com/2020/09/the-million-playlist-dataset-remastered/">1 million
                        playlists - Spotify Dataset</a>

                </li>
                <li>
                    <a href="https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks"> Spotify
                        song metadata dataset (1921 - 2016)</a>
                </li>
            </ul>
        </div>
    </div>
</body>

</html>